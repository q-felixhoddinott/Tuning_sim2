{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple modeling pipelines\n",
        "\n",
        "This notebook demonstrates building basic models on the simulated scorecard:\n",
        "- ROC curve analysis\n",
        "- Deciles analysis of outcomes by total score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Import data simulation\n",
        "from data_simulation import Scorecard\n",
        "from modeling_pipeline import ModelingPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Simulated Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create scorecard with simulated data\n",
        "scorecard = Scorecard(\n",
        "    n_rows=5000,\n",
        "    n_features=5,\n",
        "    binary_prevalence=0.20,\n",
        "    random_state=182,\n",
        "    beta=1\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(scorecard.total_scores)} samples\")\n",
        "print(f\"Binary outcome prevalence: {scorecard.binary_outcome.mean():.3f}\")\n",
        "print(f\"Total score range: {scorecard.total_scores['total_score'].min():.2f} - {scorecard.total_scores['total_score'].max():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Reuse it in multiple pipelines\n",
        "pipeline1 = ModelingPipeline(scorecard=scorecard, test_size=0.3, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir(pipeline1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline1.xgb_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ROC Curve Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate ROC curve\n",
        "y_true = scorecard.binary_outcome\n",
        "y_scores = scorecard.total_scores['total_score']\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve: Binary Outcome vs Total Score')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"AUC: {roc_auc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Deciles Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create deciles analysis\n",
        "df_analysis = pd.DataFrame({\n",
        "    'total_score': scorecard.total_scores['total_score'],\n",
        "    'binary_outcome': scorecard.binary_outcome\n",
        "})\n",
        "\n",
        "# Calculate deciles (handle duplicate edges with duplicates='drop')\n",
        "df_analysis['decile'] = pd.qcut(df_analysis['total_score'], \n",
        "                               q=10, \n",
        "                               labels=False,\n",
        "                               duplicates='drop')\n",
        "# Convert to string labels\n",
        "df_analysis['decile'] = df_analysis['decile'].apply(lambda x: f'D{x+1}')\n",
        "\n",
        "# Calculate outcome rates by decile\n",
        "decile_stats = df_analysis.groupby('decile').agg({\n",
        "    'total_score': ['count', 'mean', 'min', 'max'],\n",
        "    'binary_outcome': ['sum', 'mean']\n",
        "}).round(4)\n",
        "\n",
        "# Flatten column names\n",
        "decile_stats.columns = ['count', 'avg_score', 'min_score', 'max_score', 'positive_outcomes', 'outcome_rate']\n",
        "\n",
        "# Sort by descending average score (highest scoring decile first)\n",
        "decile_stats = decile_stats.sort_values('avg_score', ascending=False)\n",
        "\n",
        "# Add cumulative columns\n",
        "decile_stats['cumulative_total'] = decile_stats['count'].cumsum()\n",
        "decile_stats['cumulative_outcomes'] = decile_stats['positive_outcomes'].cumsum()\n",
        "decile_stats['cumulative_rate'] = (decile_stats['cumulative_outcomes'] / decile_stats['cumulative_total']).round(4)\n",
        "decile_stats['cumulative_total_percent'] = (decile_stats['cumulative_total'] / len(df_analysis)*100).round(4)\n",
        "decile_stats['cumulative_outcomes_percent'] = (decile_stats['cumulative_outcomes'] / df_analysis[\"binary_outcome\"].sum()*100).round(4)\n",
        "\n",
        "print(\"Deciles Analysis:\")\n",
        "display(decile_stats.drop([\"min_score\",\"max_score\"],axis=1))\n",
        "\n",
        "# Plot outcome rates by decile\n",
        "plt.figure(figsize=(6, 4))\n",
        "decile_stats['outcome_rate'].plot(kind='bar', color='steelblue', alpha=0.7)\n",
        "plt.title('Binary Outcome Rate by Total Score Deciles')\n",
        "plt.xlabel('Decile')\n",
        "plt.ylabel('Outcome Rate')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add overall rate line\n",
        "overall_rate = df_analysis['binary_outcome'].mean()\n",
        "plt.axhline(y=overall_rate, color='red', linestyle='--', \n",
        "            label=f'Overall Rate: {overall_rate:.3f}')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Score Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot total score distribution by outcome\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Separate scores by outcome\n",
        "scores_negative = df_analysis[df_analysis['binary_outcome'] == 0]['total_score']\n",
        "scores_positive = df_analysis[df_analysis['binary_outcome'] == 1]['total_score']\n",
        "\n",
        "plt.hist(scores_negative, bins=30, alpha=0.7, label='Negative Outcome', color='lightblue')\n",
        "plt.hist(scores_positive, bins=30, alpha=0.7, label='Positive Outcome', color='orange')\n",
        "\n",
        "plt.xlabel('Total Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Total Score Distribution by Binary Outcome')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mean score for negative outcomes: {scores_negative.mean():.3f}\")\n",
        "print(f\"Mean score for positive outcomes: {scores_positive.mean():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Tuning_sim2 (UV)",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}